{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667b5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import  KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b75b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(k=75):\n",
    "    '''\n",
    "    load dataset: 1) meta-path for urban-HIN, 2) input node feature, 3) downstream tasks, and 4) regional attribute \n",
    "    '''\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # 1) Set urban-HIN metapath\n",
    "    data['meta_paths'] = [['zone-zone'],['src-time','time-src'],['dst-time','time-dst']]\n",
    "    \n",
    "    # 2) Set feature size\n",
    "    feats = np.random.uniform(-1, 1, size=(77*4, 250))\n",
    "    feats = standardize_features(feats)\n",
    "    feats = torch.tensor(feats).float()\n",
    "    feats = feats.view(77*4,-1)\n",
    "    data['feats'] = feats\n",
    "    \n",
    "    # 3) For downstream applications\n",
    "    ic = []\n",
    "    ed = []\n",
    "    pv = []\n",
    "    em = []\n",
    "    wh = []\n",
    "    bl = []\n",
    "    hp = []\n",
    "    va = []\n",
    "    \n",
    "    for year in range(2018,2022):\n",
    "        data['heterograph_unified{}'.format(year)] = load_heteograph_unified(k, year)\n",
    "        path = './data/ride-hailing/'\n",
    "        \n",
    "        # 4) Regional Attribute Distribution\n",
    "        src_matrix = pd.read_csv(path + f'src_matrix_{year}.csv').set_index('src').to_numpy()\n",
    "        dst_matrix = pd.read_csv(path + f'dst_matrix_{year}.csv').set_index('dst').to_numpy()\n",
    "        data['src_matrix{}'.format(year)] = src_matrix\n",
    "        data['dst_matrix{}'.format(year)] = dst_matrix\n",
    "        \n",
    "        # downstream application\n",
    "        income = pd.read_pickle(\"./data/Downstream/income_CA{}.pkl\".format(year)).sort_values(['zone'])\n",
    "        education = pd.read_pickle('./data/Downstream/education_CA{}.pkl'.format(year)).sort_values(['zone'])[['zone','no_edu']]\n",
    "        poverty = pd.read_pickle('./data/Downstream/poverty_CA{}.pkl'.format(year)).sort_values(['zone'])\n",
    "        unemployed = pd.read_pickle('./data/Downstream/unemployed_CA{}.pkl'.format(year)).sort_values(['zone'])\n",
    "        race = pd.read_csv('./data/Downstream/race{}.csv'.format(year)).sort_values(['zone'])\n",
    "        value = pd.read_csv('./data/Downstream/mean_value{}.csv'.format(year)).sort_values(['zone'])\n",
    "        \n",
    "        ic.append(income)\n",
    "        ed.append(education)\n",
    "        pv.append(poverty)\n",
    "        em.append(unemployed)\n",
    "        wh.append(race[['zone','white']])\n",
    "        bl.append(race[['zone','black']])\n",
    "        hp.append(race[['zone','hispanic']])\n",
    "        va.append(value)\n",
    "        \n",
    "    ic = pd.concat(ic, axis=0).reset_index(drop=True)\n",
    "    ed = pd.concat(ed, axis=0).reset_index(drop=True)\n",
    "    pv = pd.concat(pv, axis=0).reset_index(drop=True)\n",
    "    em = pd.concat(em, axis=0).reset_index(drop=True)\n",
    "    wh = pd.concat(wh, axis=0).reset_index(drop=True)\n",
    "    bl = pd.concat(bl, axis=0).reset_index(drop=True)\n",
    "    hp = pd.concat(hp, axis=0).reset_index(drop=True)\n",
    "    va = pd.concat(va, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    data['heterograph_unified_3'] = load_heteograph_unified_total(k)\n",
    "    \n",
    "    data['income'] = ic\n",
    "    data['education'] = ed\n",
    "    data['poverty'] = pv\n",
    "    data['unemployed'] = em\n",
    "    data['white'] = wh\n",
    "    data['black'] = bl\n",
    "    data['hispanic'] = hp\n",
    "    data['value'] = va\n",
    "    \n",
    "    return data\n",
    "\n",
    "def standardize_features(feature):\n",
    "    var = np.var(feature, axis=1, keepdims=True)\n",
    "    mean = np.mean(feature, axis=1, keepdims=True)\n",
    "    std_inv = np.power(var, -0.5)\n",
    "    std_inv[np.isinf(std_inv)] = 0.\n",
    "    feature = np.multiply((feature - mean), std_inv)\n",
    "    feature = feature[np.newaxis]\n",
    "    return feature\n",
    "\n",
    "def load_heteograph_unified(k, year):\n",
    "    ''' load urban-HIN for each year'''\n",
    "    path = './data/ride-hailing/'\n",
    "    g = load_graphs(path+\"heterograph{}_k{}.bin\".format(year, k))\n",
    "    return g\n",
    "\n",
    "def load_heteograph_unified_total(k):\n",
    "    ''' losd l-urban-HIN '''\n",
    "    path = './data/ride-hailing/'\n",
    "    g = load_graphs(path+f\"heterograph1821_years_k{k}.bin\")\n",
    "    return g\n",
    "\n",
    "def evaluation_metrics(y_pred, y_test):\n",
    "    y_pred[y_pred<0] = 0\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, np.sqrt(mse), r2\n",
    "\n",
    "def regression(X_train, Y_train, X_test):\n",
    "    reg = linear_model.Ridge(alpha=1)\n",
    "    reg.fit(X_train, Y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def kf_regression(X, Y):\n",
    "    kf = KFold(n_splits=5)\n",
    "    y_preds = []\n",
    "    y_truths = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]   \n",
    "        y_pred = regression(X_train, Y_train, X_test)\n",
    "        y_preds.append(y_pred)\n",
    "        y_truths.append(Y_test)\n",
    "    return np.concatenate(y_preds), np.concatenate(y_truths)\n",
    "\n",
    "def predict_regression(emb, target):\n",
    "    emb = emb[target.index.values]\n",
    "    y_pred, y_test = kf_regression(emb, target.values[:,-1])\n",
    "    mae, rmse, r2 = evaluation_metrics(y_pred, y_test)\n",
    "    return mae, rmse, r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
